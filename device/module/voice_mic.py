import asyncio
import base64
import json
import tempfile
import time
import threading
from typing import Optional, Callable, Dict, Any
import sounddevice as sd
import paho.mqtt.client as mqtt
from pydub import AudioSegment
import os
import soundfile as sf
import numpy as np

from module.vad import VoiceActivityDetector
from module.voice_speaker import VoiceSpeaker
from config import SILENCE_THRESHOLD, SILENCE_DURATION, MIN_SPEECH_DURATION
from log import setup_logger
from config import BASE_DIR, MAX_AMP
logger = setup_logger(__name__)


class VoiceStreamer:
    """Class Ä‘á»ƒ ghi Ã¢m vÃ  gá»­i Ã¢m thanh qua MQTT hoáº·c HTTP"""

    def __init__(self, mic_index: int, sample_rate: int = 48000, chunk_duration_ms: int = 100):
        """
        Args:
            mic_name: TÃªn microphone Ä‘á»ƒ tÃ¬m device
            sample_rate: Táº§n sá»‘ láº¥y máº«u Ã¢m thanh
            chunk_duration_ms: Thá»i gian má»—i chunk (ms) cho real-time streaming
        """
        self.mic_index = mic_index
        self.sample_rate = sample_rate
        self.chunk_duration_ms = chunk_duration_ms
        self.chunk_samples = int(sample_rate * chunk_duration_ms / 1000.0)
        self.is_listening = False
        self.listening_thread = None

        # Voice Activity Detector
        self.vad = VoiceActivityDetector(
            sample_rate=sample_rate,
            silence_threshold=SILENCE_THRESHOLD,  # Äiá»u chá»‰nh theo mÃ´i trÆ°á»ng
            silence_duration=SILENCE_DURATION,
            min_speech_duration=MIN_SPEECH_DURATION
        )

        # Callback functions
        self.on_speech_start = None
        self.on_speech_complete = None
        self.on_speech_data = None

        print(f"ğŸ¤ VoiceStreamer initialized - Mic index: {self.mic_index}")

    def set_callbacks(self, on_speech_start: Callable = None,
                      on_speech_complete: Callable = None,
                      on_speech_data: Callable = None):
        """
        Thiáº¿t láº­p callback functions

        Args:
            on_speech_start: Gá»i khi báº¯t Ä‘áº§u phÃ¡t hiá»‡n giá»ng nÃ³i
            on_speech_complete: Gá»i khi hoÃ n táº¥t thu Ã¢m (audio_data, duration)
            on_speech_data: Gá»i má»—i chunk Ã¢m thanh (audio_chunk, timestamp, status)
        """
        self.on_speech_start = on_speech_start
        self.on_speech_complete = on_speech_complete
        self.on_speech_data = on_speech_data

    def start_listening(self):
        """Báº¯t Ä‘áº§u láº¯ng nghe liÃªn tá»¥c"""
        if self.is_listening:
            print("âš ï¸ Äang láº¯ng nghe rá»“i!")
            return

        self.is_listening = True
        self.listening_thread = threading.Thread(target=self._listening_loop)
        self.listening_thread.start()
        print("ğŸ‘‚ Báº¯t Ä‘áº§u láº¯ng nghe liÃªn tá»¥c...")

    def stop_listening(self):
        """Dá»«ng láº¯ng nghe"""
        self.is_listening = False
        if self.listening_thread:
            self.listening_thread.join()
        print("â¹ï¸ Dá»«ng láº¯ng nghe")

    def _listening_loop(self):
        """VÃ²ng láº·p láº¯ng nghe liÃªn tá»¥c"""
        stream = None
        try:
            stream = sd.InputStream(
                device=self.mic_index,
                channels=1,
                samplerate=self.sample_rate,
                dtype='int16',
                blocksize=self.chunk_samples
            )
            stream.start()
            print("ğŸ§ Äang láº¯ng nghe... (nÃ³i gÃ¬ Ä‘Ã³ Ä‘á»ƒ báº¯t Ä‘áº§u thu Ã¢m)")

            while self.is_listening:
                audio_chunk, overflowed = stream.read(self.chunk_samples)
                if overflowed:
                    print("âš ï¸ Audio buffer overflow!")

                if len(audio_chunk) > 0:
                    # Chuyá»ƒn Ä‘á»•i sang float32 cho VAD vÃ  Ã¡p dá»¥ng chuáº©n hÃ³a biÃªn Ä‘á»™
                    audio_float = audio_chunk.astype(np.float32) / 32768.0

                    # Xá»­ lÃ½ VAD
                    vad_result = self.vad.process_audio_chunk(audio_float)

                    # Gá»i callbacks
                    if self.on_speech_data:
                        self.on_speech_data(audio_chunk, int(
                            time.time() * 1000), vad_result)

                    if vad_result['action'] == 'speech_complete':
                        if self.on_speech_complete:
                            # Chuyá»ƒn Ä‘á»•i tá»« float32 vá» int16 Ä‘á»ƒ Ä‘áº£m báº£o Ä‘á»‹nh dáº¡ng nháº¥t quÃ¡n vá»›i record_audio
                            audio_data = vad_result['audio_data']
                            int16_audio = (
                                audio_data * 32768.0).astype(np.int16).tobytes()
                            self.on_speech_complete(
                                int16_audio, vad_result['duration'])
                            save_dir = "debug"
                            os.makedirs(save_dir, exist_ok=True)
                            file_path = os.path.join(
                                BASE_DIR, save_dir, f"audio_mic.wav")
                            try:
                                sf.write(
                                    file_path, vad_result['audio_data'], self.sample_rate, subtype='PCM_16')
                                logger.debug(
                                    f"ğŸ’¾ ÄÃ£ lÆ°u file Ã¢m thanh: {file_path}")
                            except Exception as e:
                                logger.error(
                                    f"âŒ Lá»—i khi lÆ°u file Ã¢m thanh: {e}")
                    elif vad_result['action'] == 'speaking' and not self.vad.is_speaking:
                        if self.on_speech_start:
                            self.on_speech_start()

        except Exception as e:
            print(f"âŒ Lá»—i láº¯ng nghe: {e}")
            import traceback
            traceback.print_exc()
        finally:
            # âœ… Äáº£m báº£o close stream Ä‘á»ƒ giáº£i phÃ³ng USB mic device
            if stream is not None:
                try:
                    stream.stop()
                    stream.close()
                    print("ğŸ”’ Audio stream closed and device released")
                except Exception as e:
                    print(f"âš ï¸ Error closing stream: {e}")
            self.is_listening = False

    def __del__(self):
        self.stop_listening()

    def record_audio(self, duration_sec: float) -> bytes:
        """
        Ghi Ã¢m trong thá»i gian xÃ¡c Ä‘á»‹nh vÃ  tráº£ vá» dá»¯ liá»‡u Ã¢m thanh

        Args:
            duration_sec: Thá»i gian ghi Ã¢m (giÃ¢y)

        Returns:
            bytes: Dá»¯ liá»‡u Ã¢m thanh raw (PCM 16-bit)
        """
        print(f"ğŸ™ï¸ Äang ghi Ã¢m {duration_sec}s...")

        total_samples = int(self.sample_rate * duration_sec)
        recording = sd.rec(
            total_samples,
            samplerate=self.sample_rate,
            channels=1,
            dtype='int16',
            device=self.mic_index
        )
        sd.wait()

        audio_data = recording.reshape(-1).tobytes()
        print(f"âœ… Ghi Ã¢m hoÃ n thÃ nh - {len(audio_data)} bytes")
        return audio_data



